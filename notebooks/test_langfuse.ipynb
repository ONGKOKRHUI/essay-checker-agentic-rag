{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c240ebf8",
   "metadata": {},
   "source": [
    "### Install dependencies and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede7b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e871d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LangChain has its own callback system, and Langfuse listens \n",
    "# to those callbacks to record what your chains and LLMs are doing.\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "langfuse_handler = CallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c73414e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#langchain's own callback system\n",
    "from langchain_core.callbacks import UsageMetadataCallbackHandler\n",
    "\n",
    "langchain_handler = UsageMetadataCallbackHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5370660",
   "metadata": {},
   "source": [
    "### Creating the input node for essay content upload\n",
    "- essay content: contains the content of the essay of a specific student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23185ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-16T14:12:31+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-16T14:12:31+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_content.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}, page_content='2. Student Essay Submission \\nTitle \\nBeyond Prohibition: Integrating Generative AI into Higher Education Assessment \\nand Learning \\n \\nIntroduction \\nThe rapid emergence of Generative Artificial Intelligence (GenAI) tools, such as ChatGPT \\nand Claude, has fundamentally disrupted the landscape of higher education. While \\ndigital tools have long supported academic study, GenAI’s ability to synthesise complex \\ninformation and generate human-like text presents unprecedented challenges to \\nestablished educational norms. \\nA key concern among educators is the threat these tools pose to academic integrity, \\nparticularly in relation to traditional assessment methods. However, an exclusive focus \\non these risks overlooks the significant potential of GenAI to enhance personalised \\nlearning. \\nThis essay argues that although GenAI undermines the reliability of conventional essay-\\nbased assessments, it also offers meaningful benefits for student engagement and skill \\ndevelopment. As a result, universities should move beyond outright prohibition and \\nadopt a policy of critical integration by redesigning assessments to coexist with \\nemerging technologies. The discussion will first explore challenges to academic \\nintegrity, then examine learning benefits, and finally address the need for assessment \\nreform. \\n \\nBody Paragraph 1: Challenges to Academic Integrity \\nThe most immediate challenge posed by GenAI is the erosion of academic integrity in \\ntraditional written assessments. Coursework that relies heavily on knowledge \\nsummarisation or standard essay writing is especially vulnerable to AI-generated \\nplagiarism. Baron (2023) highlights that existing plagiarism detection software \\nincreasingly struggles to distinguish between human and AI-produced text, creating a \\n“crisis of trust” in grading systems. \\nThis issue stems from the way GenAI generates original outputs by predicting word \\nsequences rather than copying text verbatim, allowing it to evade similarity-based \\ndetection tools (Zhang & Li, 2024). As a result, students can submit high-quality work \\nwith limited cognitive engagement, undermining the credibility of academic \\nqualifications.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-16T14:12:31+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-16T14:12:31+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_content.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2'}, page_content='Although some institutions have implemented strict bans, enforcement is largely \\nineffective outside controlled examination settings. Consequently, continued reliance \\non take-home essays as a primary measure of learning is becoming increasingly \\nunsustainable. \\n \\nBody Paragraph 2: Benefits for Student Learning \\nDespite integrity concerns, GenAI offers significant opportunities to enhance learning \\nthrough personalisation and instant feedback. Unlike human tutors, AI tools can provide \\ncontinuous academic support without time constraints. Chen et al. (2024) demonstrate \\nthat when AI is used as a Socratic tutor—prompting learners through guided questioning \\nrather than direct answers—students show improved critical thinking skills, particularly \\nin STEM disciplines. \\nThis indicates that GenAI can effectively scaffold learning by adapting explanations to \\nindividual proficiency levels. Additionally, language and formatting support offered by AI \\nallows students, especially second-language writers, to focus on higher-order thinking \\nrather than surface-level accuracy (EduTech Future, 2023). \\nTherefore, rather than replacing learning, GenAI can function as an assistive tool that \\nbroadens access to academic support and enhances learner autonomy. \\n \\nBody Paragraph 3: The Need for Assessment Reform \\nGiven both the risks and benefits of GenAI, assessment reform represents the most \\nsustainable response. Universities must shift from evaluating what students know to \\nassessing how they apply knowledge in conjunction with technology. A prohibition-\\nfocused approach fails to acknowledge that AI literacy is increasingly expected in \\nprofessional contexts (World Economic Forum, 2024). \\nAssessment methods should evolve to include oral examinations, reflective portfolios, \\nand tasks that require critical evaluation of AI-generated outputs. The University of \\nManchester Teaching Framework (2023) emphasises the importance of prioritising \\nlearning processes over final products, encouraging students to demonstrate inquiry, \\nverification, and reflection skills. \\nBy embedding AI use within assessment design—such as asking students to critique \\nflawed AI responses—institutions can cultivate critical digital literacy that aligns with \\ncontemporary academic and workplace demands. \\n \\nConclusion'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-16T14:12:31+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-16T14:12:31+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_content.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3'}, page_content='In conclusion, the integration of GenAI in higher education presents a clear paradox: it \\nthreatens the integrity of traditional assessments while simultaneously offering \\npowerful tools for personalised learning. As this essay has demonstrated, banning AI \\ntechnologies is an impractical and short-sighted response that leaves students \\nunprepared for a technology-driven future. \\nInstead, universities should adopt a balanced approach that integrates AI literacy into \\ncurricula while redesigning assessments to prioritise critical thinking, authenticity, and \\nreflective practice. Ultimately, the rise of GenAI does not mark the decline of higher \\neducation but signals an essential evolution towards more resilient and relevant \\npedagogical models.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_content.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce4dc0",
   "metadata": {},
   "source": [
    "### Create Fact Extractor LLM \n",
    "- to extract facts from essay content and output a JSON format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4daba6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683df887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "class FactsInfo(BaseModel):\n",
    "    statement: str = Field(\n",
    "            ..., \n",
    "            description=\"The factual claim made by the student.\"\n",
    "        )\n",
    "    source_quote: str = Field(\n",
    "            ..., \n",
    "            description=\"The exact sentence or phrase from the essay where this fact is mentioned.\"\n",
    "        )\n",
    "    page_number: int = Field(\n",
    "            ..., \n",
    "            description=\"The page number where this fact was found.\"\n",
    "        )\n",
    "\n",
    "# 2. Define the container for the facts (the final JSON structure)\n",
    "class FactExtraction(BaseModel):\n",
    "    facts: List[FactsInfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the Model (DeepSeek via OpenAI API) ---\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=\"https://api.siliconflow.cn/v1\",\n",
    "    temperature=0,  # Keep it 0 for consistent analysis\n",
    "    #max_tokens = 2048,\n",
    "    #timeout = 60,\n",
    ")\n",
    "\n",
    "# Bind the schema to the model\n",
    "structured_llm = llm.with_structured_output(FactExtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a7a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert fact-checker. \n",
    "Extract every distinct factual claim made in the text provided.\n",
    "Ignore opinions or transitional phrases.\n",
    "For every fact, you must provide the exact quote from the text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e235c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "extraction_chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bcf6cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3 pages using Deepseek...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10856\\2581873400.py:23: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  fact_dict = fact.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed page 1 out of 3 pages\n",
      "Processed page 2 out of 3 pages\n",
      "Processed page 3 out of 3 pages\n"
     ]
    }
   ],
   "source": [
    "all_facts_with_metadata = []\n",
    "\n",
    "print(f\"Processing {len(docs)} pages using Deepseek...\")\n",
    "\n",
    "for doc in docs:\n",
    "    page_num = doc.metadata.get('page', 0) + 1\n",
    "    page_content = doc.page_content\n",
    "    \n",
    "    # Skip empty pages to save API calls\n",
    "    if not page_content.strip():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # We only send the text to the LLM\n",
    "        # We use the langfuse_handler to record what the LLM is doing\n",
    "        result = extraction_chain.invoke({\"text\": page_content},\n",
    "                                         config={\"callbacks\": [langfuse_handler, langchain_handler]})\n",
    "        \n",
    "        # We attach the page number manually here.\n",
    "        # This is safer than asking the LLM to guess the page number.\n",
    "        if result and result.facts:\n",
    "            for fact in result.facts:\n",
    "                fact_dict = fact.dict()\n",
    "                fact_dict['page_number'] = page_num\n",
    "                all_facts_with_metadata.append(fact_dict)\n",
    "        print(f\"Processed page {page_num} out of {len(docs)} pages\")\n",
    "\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page_num}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da103ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'statement': 'Generative Artificial Intelligence (GenAI) tools, such as ChatGPT and Claude, have fundamentally disrupted the landscape of higher education.', 'source_quote': 'The rapid emergence of Generative Artificial Intelligence (GenAI) tools, such as ChatGPT and Claude, has fundamentally disrupted the landscape of higher education.', 'page_number': 1}\n",
      "{'statement': 'GenAI has the ability to synthesise complex information and generate human-like text.', 'source_quote': 'GenAI’s ability to synthesise complex information and generate human-like text presents unprecedented challenges to established educational norms.', 'page_number': 1}\n",
      "{'statement': 'Educators are concerned about the threat GenAI tools pose to academic integrity, particularly in relation to traditional assessment methods.', 'source_quote': 'A key concern among educators is the threat these tools pose to academic integrity, particularly in relation to traditional assessment methods.', 'page_number': 1}\n",
      "{'statement': 'Existing plagiarism detection software increasingly struggles to distinguish between human and AI-produced text.', 'source_quote': \"Baron (2023) highlights that existing plagiarism detection software increasingly struggles to distinguish between human and AI-produced text, creating a 'crisis of trust' in grading systems.\", 'page_number': 1}\n",
      "{'statement': 'GenAI generates original outputs by predicting word sequences rather than copying text verbatim.', 'source_quote': 'This issue stems from the way GenAI generates original outputs by predicting word sequences rather than copying text verbatim, allowing it to evade similarity-based detection tools (Zhang & Li, 2024).', 'page_number': 1}\n",
      "{'statement': 'Students can submit high-quality work with limited cognitive engagement.', 'source_quote': 'As a result, students can submit high-quality work with limited cognitive engagement, undermining the credibility of academic qualifications.', 'page_number': 1}\n",
      "{'statement': 'When AI is used as a Socratic tutor, students show improved critical thinking skills, particularly in STEM disciplines.', 'source_quote': 'Chen et al. (2024) demonstrate that when AI is used as a Socratic tutor—prompting learners through guided questioning rather than direct answers—students show improved critical thinking skills, particularly in STEM disciplines.', 'page_number': 2}\n",
      "{'statement': \"AI's language and formatting support allows students, especially second-language writers, to focus on higher-order thinking rather than surface-level accuracy.\", 'source_quote': 'language and formatting support offered by AI allows students, especially second-language writers, to focus on higher-order thinking rather than surface-level accuracy (EduTech Future, 2023).', 'page_number': 2}\n",
      "{'statement': 'AI literacy is increasingly expected in professional contexts.', 'source_quote': 'AI literacy is increasingly expected in professional contexts (World Economic Forum, 2024).', 'page_number': 2}\n",
      "{'statement': 'The University of Manchester Teaching Framework emphasises prioritising learning processes over final products, encouraging students to demonstrate inquiry, verification, and reflection skills.', 'source_quote': 'The University of Manchester Teaching Framework (2023) emphasises the importance of prioritising learning processes over final products, encouraging students to demonstrate inquiry, verification, and reflection skills.', 'page_number': 2}\n"
     ]
    }
   ],
   "source": [
    "for fact in all_facts_with_metadata:\n",
    "    print(fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b8d5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepseek-ai/DeepSeek-V3': {'total_tokens': 1858,\n",
       "  'output_tokens': 783,\n",
       "  'input_token_details': {},\n",
       "  'input_tokens': 1075,\n",
       "  'output_token_details': {}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print langchain callback to track token usage\n",
    "langchain_handler.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8aeb336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 25 records to C:\\Users\\HP\\Documents\\repos\\essay-checker-agentic-rag\\data\\processed\\extracted_facts.jsonl\n"
     ]
    }
   ],
   "source": [
    "#export to JSON file\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "FACTS_JSON_PATH = \"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\processed\\\\extracted_facts.jsonl\"\n",
    "output_path = Path(FACTS_JSON_PATH)\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(FACTS_JSON_PATH, 'w', encoding='utf-8') as f:\n",
    "    for fact in all_facts_with_metadata:\n",
    "        f.write(json.dumps(fact) + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(all_facts_with_metadata)} records to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
