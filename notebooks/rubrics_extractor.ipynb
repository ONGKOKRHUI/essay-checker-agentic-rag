{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c240ebf8",
   "metadata": {},
   "source": [
    "### Install dependencies and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede7b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294bfeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23185ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-16T14:21:40+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-16T14:21:40+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_rubric.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}, page_content='ESAC Integrated Writing Assessment (IWA) \\nRubric: Generative AI in Higher Education \\nEssay Topic \\nThe integration of Generative Artificial Intelligence (GenAI) in higher education: \\nchallenges to academic integrity, benefits for learning, and the extent of \\ninstitutional adoption. \\n \\nAssessment Criteria Overview \\nCriterion Weight \\n1. Task Response & Argument 20% \\n2. Critical Thinking & Evaluation 20% \\n3. Use of Sources & Referencing 20% \\n4. Academic Writing Style & Register 15% \\n5. Organisation & Cohesion 15% \\n6. Language Accuracy & Control 10% \\nTotal 100% \\n \\n1. Task Response & Argument (20%) \\nBand Descriptor \\nBand 9 \\n(Excellent) \\nFully addresses all parts of the task with a clear, insightful, and \\noriginal argument. Demonstrates a nuanced understanding of \\nGenAI’s challenges and benefits. Position on university \\nadoption is sophisticated and consistently sustained. \\nBand 8 (Strong) \\nAddresses all aspects of the task effectively with a clear and \\nwell-developed argument. Demonstrates strong understanding \\nof the topic with minor lapses in depth or nuance. Position is \\nclear and well supported. \\nBand 7 (Good) Addresses the task competently but may place uneven \\nemphasis on certain aspects (e.g., more challenges than'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-16T14:21:40+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-16T14:21:40+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_rubric.pdf', 'total_pages': 5, 'page': 1, 'page_label': '2'}, page_content='Band Descriptor \\nbenefits). Argument is clear but may lack refinement or full \\nbalance. \\nBand 6 \\n(Satisfactory) \\nResponds to the task but may partially address key elements or \\npresent a simplistic position. Argument may be descriptive \\nrather than analytical. \\nBand 5 and below \\n(Limited–Poor) \\nDoes not adequately address the task. Argument may be \\nunclear, underdeveloped, or largely descriptive with significant \\nomissions. \\n \\n2. Critical Thinking & Evaluation (20%) \\nBand Descriptor \\nBand 9 \\nDemonstrates excellent critical engagement with sources and ideas. \\nEvaluates implications, limitations, and counterarguments insightfully. \\nShows independent thinking and synthesis. \\nBand 8 \\nDemonstrates strong critical evaluation of issues and sources. Ideas \\nare analysed rather than merely described, with some \\nacknowledgement of complexity. \\nBand 7 \\nShows reasonable critical thinking but analysis may be uneven or rely \\ntoo heavily on source perspectives. Limited exploration of \\ncounterarguments. \\nBand 6 Limited critical evaluation; tends to summarise sources rather than \\nanalyse them. Few links between evidence and argument. \\nBand 5 \\nand \\nbelow \\nMinimal or no critical engagement. Largely descriptive or opinion-based \\nwith weak support. \\n \\n3. Use of Sources & Referencing (20%)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-16T14:21:40+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-16T14:21:40+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_rubric.pdf', 'total_pages': 5, 'page': 2, 'page_label': '3'}, page_content='Band Descriptor \\nBand 9 \\nIntegrates a wide range of high-quality academic sources seamlessly. \\nParaphrasing is sophisticated and accurate. Referencing is fully \\nconsistent with ESAC conventions. \\nBand 8 \\nUses an appropriate range of sources effectively. Paraphrasing is \\naccurate with only very minor lapses. Referencing is largely correct \\nwith occasional minor errors. \\nBand 7 Uses relevant sources but integration may be mechanical. Some \\nparaphrasing issues or minor referencing inconsistencies. \\nBand 6 \\nLimited range of sources or over-reliance on a few. Paraphrasing may be \\nweak or too close to original wording. Referencing errors are \\nnoticeable. \\nBand 5 \\nand \\nbelow \\nInadequate sourcing, poor paraphrasing, or frequent referencing errors. \\nPossible risk of plagiarism. \\n \\n4. Academic Writing Style & Register (15%) \\nBand Descriptor \\nBand 9 Consistently formal, precise, and sophisticated academic tone. \\nExcellent control of discipline-appropriate vocabulary. \\nBand 8 Appropriate academic register throughout with strong lexical choice. \\nMinor occasional slips do not affect clarity. \\nBand 7 Generally academic but may include some informal phrasing or \\nrepetitive vocabulary. \\nBand 6 Inconsistent academic tone. Overly simple or conversational \\nlanguage appears. \\nBand 5 and \\nbelow Inappropriate register with frequent informal or unclear language. \\n \\n5. Organisation & Cohesion (15%)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-16T14:21:40+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-16T14:21:40+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_rubric.pdf', 'total_pages': 5, 'page': 3, 'page_label': '4'}, page_content='Band Descriptor \\nBand 9 \\nExceptionally well-structured with clear progression of ideas. \\nParagraphing is logical and cohesive, with excellent use of linking \\ndevices. \\nBand 8 Clear and logical structure. Paragraphs are well-developed with \\neffective cohesion. Minor organisational lapses may occur. \\nBand 7 Overall structure is clear, but paragraph development or transitions \\nmay be uneven. \\nBand 6 Organisation is weak or repetitive. Ideas may be loosely connected. \\nBand 5 and \\nbelow Poor organisation. Lack of coherence and clear paragraph structure. \\n \\n6. Language Accuracy & Control (10%) \\nBand Descriptor \\nBand 9 Near-native accuracy. Errors are extremely rare and insignificant. \\nBand 8 High level of grammatical accuracy with only occasional minor \\nerrors that do not impede meaning. \\nBand 7 Some grammatical or lexical errors, but meaning remains generally \\nclear. \\nBand 6 Frequent errors that occasionally interfere with clarity. \\nBand 5 and \\nbelow Persistent errors that significantly impede understanding. \\n \\nOverall Band Guide \\nFinal Band Performance Summary \\nBand 9 Outstanding, publication-level academic writing \\nBand 8 Strong, effective university-level academic writing \\nBand 7 Competent and clear, but lacks depth or polish'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-16T14:21:40+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-16T14:21:40+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_rubric.pdf', 'total_pages': 5, 'page': 4, 'page_label': '5'}, page_content='Final Band Performance Summary \\nBand 6 Adequate but limited academic performance \\nBand ≤5 Insufficient for ESAC IWA standards')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\raw\\\\essay_rubric.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a5aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Rubric Schema ---\n",
    "# This structure is critical for the Final Judge. \n",
    "# It needs to know exactly what an \"A\" looks like vs. a \"B\" for EACH criterion.\n",
    "\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 1. Performance Level (The 'Cell' in the table)\n",
    "class PerformanceLevel(BaseModel):\n",
    "    grade_label: str = Field(..., description=\"The label (e.g., 'High Distinction', 'A', 'Band 5').\")\n",
    "    score_range: str = Field(..., description=\"The point range (e.g., '80-100', '16-20').\")\n",
    "    # ESAC rubrics often have multiple bullet points per cell. Capturing them as a list is better.\n",
    "    descriptor_points: List[str] = Field(\n",
    "        ..., \n",
    "        description=\"A list of specific qualifiers/bullets found in this cell (e.g. ['Uses complex grammar', 'Minimal errors']).\"\n",
    "    )\n",
    "\n",
    "# 2. Criterion (The 'Row' in the table)\n",
    "class AssessmentCriterion(BaseModel):\n",
    "    category: Optional[str] = Field(\n",
    "        None, \n",
    "        description=\"The broader category this criterion belongs to (e.g., 'Language', 'Content', 'Structure').\"\n",
    "    )\n",
    "    name: str = Field(..., description=\"The specific skill being assessed (e.g., 'Referencing Conventions', 'Critical Analysis').\")\n",
    "    weight: str = Field(..., description=\"The weight of this criterion (e.g., '30%', '10 marks').\")\n",
    "    levels: List[PerformanceLevel] = Field(..., description=\"The grading scale for this specific criterion.\")\n",
    "\n",
    "# 3. The Full Rubric\n",
    "class RubricExtractionResult(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the rubric.\")\n",
    "    context_notes: List[str] = Field(\n",
    "        default_factory=list, \n",
    "        description=\"Any global rules found (e.g., 'Plagiarism results in 0', 'Word count penalty').\"\n",
    "    )\n",
    "    criteria: List[AssessmentCriterion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452f86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the Model (DeepSeek via OpenAI API) ---\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=\"https://api.siliconflow.cn/v1\",\n",
    "    temperature=0  # Keep it 0 for consistent analysis\n",
    ")\n",
    "\n",
    "# Bind the schema to the model\n",
    "structured_llm = llm.with_structured_output(RubricExtractionResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a7a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an AI specialized in \"Rubric Digitization\". \n",
    "Your task is to extract grading criteria from raw PDF text (which often has broken table formatting) and structure it into a precise JSON format.\n",
    "\n",
    "**Extraction Rules:**\n",
    "1. **Reconstruct the Grid:** Input text often comes from tables where rows and columns are jumbled. You must logically group text based on context.\n",
    "2. **Identify Criteria (Rows):** Look for distinct skills being assessed (e.g., \"Argumentation\", \"Structure\").\n",
    "3. **Identify Levels (Columns):** Look for grade headers (e.g., \"HD\", \"D\", \"C\", \"P\") and map the descriptions under them correctly.\n",
    "4. **Capture Descriptors:** The most important output is the **description** text for each level. This is what the grading AI will use to judge the student.\n",
    "\n",
    "If a criterion has a weight (e.g., \"20%\"), extract it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e235c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "extraction_chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcf6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Logic ---\n",
    "\n",
    "def extract_rubric(pdf_path: str):\n",
    "    print(f\"Loading Rubric PDF from: {pdf_path}\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    if not docs:\n",
    "        print(\"Error: No documents found.\")\n",
    "        return None\n",
    "\n",
    "    # Rubrics often span 1-2 pages. Merging them helps the LLM see the whole table structure.\n",
    "    full_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    \n",
    "    print(f\"Digitizing Rubric ({len(full_text)} characters)...\")\n",
    "    \n",
    "    try:\n",
    "        result = extraction_chain.invoke({\"text\": full_text})\n",
    "        return result.dict()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during rubric extraction: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da103ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Rubric PDF from: C:\\Users\\HP\\Documents\\repos\\essay-checker-agentic-rag\\data\\raw\\essay_rubric.pdf\n",
      "Digitizing Rubric (5293 characters)...\n",
      "{'title': 'ESAC Integrated Writing Assessment (IWA) Rubric', 'context_notes': ['Rubric for ESAC Integrated Writing Assessment (IWA) on Generative AI in Higher Education', 'Essay covers challenges to academic integrity, benefits for learning, and institutional adoption'], 'criteria': [{'category': 'Task Response & Argument', 'name': 'Task Response & Argument', 'weight': '20%', 'levels': [{'grade_label': 'Band 9 (Excellent)', 'score_range': '20%', 'descriptor_points': ['Fully addresses all parts of the task with a clear, insightful, and original argument', 'Demonstrates a nuanced understanding of GenAI’s challenges and benefits', 'Position on university adoption is sophisticated and consistently sustained']}, {'grade_label': 'Band 8 (Strong)', 'score_range': '20%', 'descriptor_points': ['Addresses all aspects of the task effectively with a clear and well-developed argument', 'Demonstrates strong understanding of the topic with minor lapses in depth or nuance', 'Position is clear and well supported']}, {'grade_label': 'Band 7 (Good)', 'score_range': '20%', 'descriptor_points': ['Addresses the task competently but may place uneven emphasis on certain aspects', 'Argument is clear but may lack refinement or full balance']}, {'grade_label': 'Band 6 (Satisfactory)', 'score_range': '20%', 'descriptor_points': ['Responds to the task but may partially address key elements or present a simplistic position', 'Argument may be descriptive rather than analytical']}, {'grade_label': 'Band 5 and below (Limited–Poor)', 'score_range': '20%', 'descriptor_points': ['Does not adequately address the task', 'Argument may be unclear, underdeveloped, or largely descriptive with significant omissions']}]}, {'category': 'Critical Thinking & Evaluation', 'name': 'Critical Thinking & Evaluation', 'weight': '20%', 'levels': [{'grade_label': 'Band 9', 'score_range': '20%', 'descriptor_points': ['Demonstrates excellent critical engagement with sources and ideas', 'Evaluates implications, limitations, and counterarguments insightfully', 'Shows independent thinking and synthesis']}, {'grade_label': 'Band 8', 'score_range': '20%', 'descriptor_points': ['Demonstrates strong critical evaluation of issues and sources', 'Ideas are analysed rather than merely described, with some acknowledgement of complexity']}, {'grade_label': 'Band 7', 'score_range': '20%', 'descriptor_points': ['Shows reasonable critical thinking but analysis may be uneven or rely too heavily on source perspectives', 'Limited exploration of counterarguments']}, {'grade_label': 'Band 6', 'score_range': '20%', 'descriptor_points': ['Limited critical evaluation; tends to summarise sources rather than analyse them', 'Few links between evidence and argument']}, {'grade_label': 'Band 5 and below', 'score_range': '20%', 'descriptor_points': ['Minimal or no critical engagement', 'Largely descriptive or opinion-based with weak support']}]}, {'category': 'Use of Sources & Referencing', 'name': 'Use of Sources & Referencing', 'weight': '20%', 'levels': [{'grade_label': 'Band 9', 'score_range': '20%', 'descriptor_points': ['Integrates a wide range of high-quality academic sources seamlessly', 'Paraphrasing is sophisticated and accurate', 'Referencing is fully consistent with ESAC conventions']}, {'grade_label': 'Band 8', 'score_range': '20%', 'descriptor_points': ['Uses an appropriate range of sources effectively', 'Paraphrasing is accurate with only very minor lapses', 'Referencing is largely correct with occasional minor errors']}, {'grade_label': 'Band 7', 'score_range': '20%', 'descriptor_points': ['Uses relevant sources but integration may be mechanical', 'Some paraphrasing issues or minor referencing inconsistencies']}, {'grade_label': 'Band 6', 'score_range': '20%', 'descriptor_points': ['Limited range of sources or over-reliance on a few', 'Paraphrasing may be weak or too close to original wording', 'Referencing errors are noticeable']}, {'grade_label': 'Band 5 and below', 'score_range': '20%', 'descriptor_points': ['Inadequate sourcing, poor paraphrasing, or frequent referencing errors', 'Possible risk of plagiarism']}]}, {'category': 'Academic Writing Style & Register', 'name': 'Academic Writing Style & Register', 'weight': '15%', 'levels': [{'grade_label': 'Band 9', 'score_range': '15%', 'descriptor_points': ['Consistently formal, precise, and sophisticated academic tone', 'Excellent control of discipline-appropriate vocabulary']}, {'grade_label': 'Band 8', 'score_range': '15%', 'descriptor_points': ['Appropriate academic register throughout with strong lexical choice', 'Minor occasional slips do not affect clarity']}, {'grade_label': 'Band 7', 'score_range': '15%', 'descriptor_points': ['Generally academic but may include some informal phrasing or repetitive vocabulary']}, {'grade_label': 'Band 6', 'score_range': '15%', 'descriptor_points': ['Inconsistent academic tone', 'Overly simple or conversational language appears']}, {'grade_label': 'Band 5 and below', 'score_range': '15%', 'descriptor_points': ['Inappropriate register with frequent informal or unclear language']}]}, {'category': 'Organisation & Cohesion', 'name': 'Organisation & Cohesion', 'weight': '15%', 'levels': [{'grade_label': 'Band 9', 'score_range': '15%', 'descriptor_points': ['Exceptionally well-structured with clear progression of ideas', 'Paragraphing is logical and cohesive, with excellent use of linking devices']}, {'grade_label': 'Band 8', 'score_range': '15%', 'descriptor_points': ['Clear and logical structure', 'Paragraphs are well-developed with effective cohesion', 'Minor organisational lapses may occur']}, {'grade_label': 'Band 7', 'score_range': '15%', 'descriptor_points': ['Overall structure is clear, but paragraph development or transitions may be uneven']}, {'grade_label': 'Band 6', 'score_range': '15%', 'descriptor_points': ['Organisation is weak or repetitive', 'Ideas may be loosely connected']}, {'grade_label': 'Band 5 and below', 'score_range': '15%', 'descriptor_points': ['Poor organisation', 'Lack of coherence and clear paragraph structure']}]}, {'category': 'Language Accuracy & Control', 'name': 'Language Accuracy & Control', 'weight': '10%', 'levels': [{'grade_label': 'Band 9', 'score_range': '10%', 'descriptor_points': ['Near-native accuracy', 'Errors are extremely rare and insignificant']}, {'grade_label': 'Band 8', 'score_range': '10%', 'descriptor_points': ['High level of grammatical accuracy with only occasional minor errors that do not impede meaning']}, {'grade_label': 'Band 7', 'score_range': '10%', 'descriptor_points': ['Some grammatical or lexical errors, but meaning remains generally clear']}, {'grade_label': 'Band 6', 'score_range': '10%', 'descriptor_points': ['Frequent errors that occasionally interfere with clarity']}, {'grade_label': 'Band 5 and below', 'score_range': '10%', 'descriptor_points': ['Persistent errors that significantly impede understanding']}]}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20828\\2679192163.py:19: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  return result.dict()\n"
     ]
    }
   ],
   "source": [
    "rubric_json = extract_rubric(pdf_path)\n",
    "print(rubric_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8aeb336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3 records to C:\\Users\\HP\\Documents\\repos\\essay-checker-agentic-rag\\data\\processed\\extracted_rubrics.json\n"
     ]
    }
   ],
   "source": [
    "#export to JSON file\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "RUBRICS_JSON_PATH = \"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\processed\\\\extracted_rubrics.json\"\n",
    "output_path = Path(RUBRICS_JSON_PATH)\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(RUBRICS_JSON_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(rubric_json, indent=2))\n",
    "\n",
    "print(f\"Saved {len(rubric_json)} records to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f4b2f9",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# --- Step 1: Define the Rubric Schema ---\n",
    "# This structure is critical for the Final Judge. \n",
    "# It needs to know exactly what an \"A\" looks like vs. a \"B\" for EACH criterion.\n",
    "\n",
    "class PerformanceLevel(BaseModel):\n",
    "    grade_label: str = Field(..., description=\"The label for this level (e.g., 'High Distinction', 'A', 'Level 4').\")\n",
    "    score_range: str = Field(..., description=\"The point range or percentage for this level (e.g., '80-100', '16-20 points').\")\n",
    "    description: str = Field(..., description=\"The detailed text describing the requirements to achieve this specific level.\")\n",
    "\n",
    "class AssessmentCriterion(BaseModel):\n",
    "    name: str = Field(..., description=\"The name of the criterion (e.g., 'Critical Thinking', 'Grammar & Syntax').\")\n",
    "    weight: str = Field(..., description=\"The weight of this criterion (e.g., '30%', '20 points').\")\n",
    "    levels: List[PerformanceLevel] = Field(..., description=\"The breakdown of how this specific criterion is graded across different performance levels.\")\n",
    "\n",
    "class RubricExtractionResult(BaseModel):\n",
    "    title: str = Field(..., description=\"The title of the assignment or rubric.\")\n",
    "    total_points: str = Field(..., description=\"The total points possible for the assignment.\")\n",
    "    criteria: List[AssessmentCriterion] = Field(..., description=\"The list of all assessment criteria found in the rubric.\")\n",
    "\n",
    "# --- Step 2: Setup the Model (DeepSeek via OpenAI API) ---\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=\"https://api.siliconflow.cn/v1\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Bind the schema\n",
    "structured_llm = llm.with_structured_output(RubricExtractionResult)\n",
    "\n",
    "# --- Step 3: Refined Prompt for Table Reconstruction ---\n",
    "system_prompt = \"\"\"\n",
    "You are an AI specialized in \"Rubric Digitization\". \n",
    "Your task is to extract grading criteria from raw PDF text (which often has broken table formatting) and structure it into a precise JSON format.\n",
    "\n",
    "**Extraction Rules:**\n",
    "1. **Reconstruct the Grid:** Input text often comes from tables where rows and columns are jumbled. You must logically group text based on context.\n",
    "2. **Identify Criteria (Rows):** Look for distinct skills being assessed (e.g., \"Argumentation\", \"Structure\").\n",
    "3. **Identify Levels (Columns):** Look for grade headers (e.g., \"HD\", \"D\", \"C\", \"P\") and map the descriptions under them correctly.\n",
    "4. **Capture Descriptors:** The most important output is the **description** text for each level. This is what the grading AI will use to judge the student.\n",
    "\n",
    "If a criterion has a weight (e.g., \"20%\"), extract it.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "chain = prompt | structured_llm\n",
    "\n",
    "# --- Step 4: Execution Logic ---\n",
    "\n",
    "def extract_rubric(pdf_path: str):\n",
    "    print(f\"Loading Rubric PDF from: {pdf_path}\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    if not docs:\n",
    "        print(\"Error: No documents found.\")\n",
    "        return None\n",
    "\n",
    "    # Rubrics often span 1-2 pages. Merging them helps the LLM see the whole table structure.\n",
    "    full_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    \n",
    "    print(f\"Digitizing Rubric ({len(full_text)} characters)...\")\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\"text\": full_text})\n",
    "        return result.dict()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during rubric extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Usage Example ---\n",
    "# pdf_path = r\"C:\\Users\\HP\\Documents\\rubrics\\assignment_1_rubric.pdf\"\n",
    "# rubric_json = extract_rubric(pdf_path)\n",
    "\n",
    "# if rubric_json:\n",
    "#     import json\n",
    "#     print(json.dumps(rubric_json, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
