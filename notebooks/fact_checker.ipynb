{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafe57d7",
   "metadata": {},
   "source": [
    "### Fact Checker\n",
    "- receives a json of facts, loop through them\n",
    "- for each fact, queries the knowledge base tool to check\n",
    "- if not found, uses web search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fdd3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Literal, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee108774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SILICON_FLOW_BASE_URL = os.getenv(\"SILICON_FLOW_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2dcd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths\n",
    "FACTS_JSONL_PATH = \"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\processed\\\\extracted_facts.jsonl\"\n",
    "ALLOWED_DOMAINS = \"\" # can set to wikipedia domain if want to limit\n",
    "OUTPUT_PATH = \"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\processed\\\\fact_checking_output.json\"\n",
    "DOCUMENT_FOLDER_PATH = \"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\knowledge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "675b5186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-20T19:55:41+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-20T19:55:41+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\knowledge_base\\\\AI_and_assessment_in_higher_education.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='AI and assessment in higher education \\nhttps://www.timeshighereducation.com/campus/ai-and-assessment-higher-\\neducation  \\nThreat or opportunity? Advice for using, managing and embedding artificial intelligence \\nin university assessment, skills development and task design \\nNo sooner had generative AI (GenAI) tools, such as ChatGPT, ignited fears in universities \\nabout risk to assessment practices and academic integrity, than academics began \\nworking out how to embrace it to save time and enrich student skills such as critical \\nthinking and analysis. This has required consideration of not only how to use artificial \\nintelligence (AI) in future university assessment but also a rethink of past exam, \\nassignment and evaluation practices. This diverse collection of resources includes \\nadvice on how to engineer prompts, use AI for authentic assessment design, whether to \\nlean into AI-detection tools, how to build digital literacy and AI’s role in developing soft \\nskills in lifelong learning. \\nGet started with 25 applications of ChatGPT and generative AI in learning and \\nassessment shared in the form of prompts by Seb Dianati and Suman Laudari of \\nCharles Darwin University. \\nHow AI can affect formative and summative assessment design \\nAs AI technologies become ubiquitous, educators must consider how to design \\nassignments that work with these tools in productive ways to aid learning and AI \\nliteracy. These resources explore practical ways to incorporate AI into task design and \\nassessment strategies, taking into account students’ differing skill levels.  \\nHow students’ GenAI skills and reflection affect assignment instructions: The \\nability to use GenAI is akin to time management or other learning skills that require \\npractice. Here, Vincent Spezzo and Ilya Gokhman from Georgia Tech’s Center for 21st \\nCentury Universities offer tips to make sure lecturers’ instructions make sense to \\nstudents with differing levels of AI experience. \\nAI and assessment redesign: a four-step process: If GenAI tools mean institutions \\ncan no longer assure the integrity of individual assessments, the sector must focus on \\nassuring the integrity of overall awards, write Samuel Doherty and Steven Warburton of \\nthe University of Newcastle, Australia. \\nDesigning assessments with generative AI in mind: The proliferation of AI requires a \\nbalance between thoughtfully mitigating and responsibly promoting students’ use of the \\nnew tools. Kate Crane of Dalhousie University offers four strategies to help faculty chart \\na path forward. \\nAI as a learning aid for critical thinking'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-20T19:55:41+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-20T19:55:41+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\knowledge_base\\\\AI_and_assessment_in_higher_education.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content=\"Critical thinking is a future-proof skill in high demand from employers. The arrival of \\nartificial intelligence, specifically GenAI, makes honing critical thinking among students \\nand academics even more vital since large language models excel in lower-order tasks \\nsuch as reproducing information but are limited in their higher order analytical abilities. \\nThese resources explore how to use GenAI to train students in critical analysis and \\ninterrogation.  \\nUse artificial intelligence to get your students thinking critically: Urbi Ghosh \\nof Colorado State University Global shows how GenAI can enhance students’ analytical \\nabilities when used as a critical thinking scaffold. \\nIn an artificially intelligent age, frame higher education around a new kind of \\nthinking: A helpful by-product emerging from the advent of AI is that we are beginning to \\nreflect more critically on the way we think, writes David Holland of the University of East \\nAnglia as he argues for a reimagining of the educational mission. \\nAI detection, cheating and academic integrity \\nThey are questions plaguing many university educators – how can you detect if students \\nhave used artificial intelligence for their work? And does it matter if they have? From the \\ndependability of AI detectors to common features of AI generated content, these \\nresources explore how academics might identify GenAI input and combat cheating but \\nalso whether a new understanding of academic integrity is needed for the digital age. \\nCan academics tell the difference between AI-generated and human-authored \\ncontent? A recent study asked students and academics to distinguish between \\nscientific abstracts generated by ChatGPT and those written by humans. The University \\nof Adelaide's Omar Siddique analyses the results. \\nWill ChatGPT change our definitions of cheating? We can’t yet know if we have a full \\ntaxonomy of ChatGPT-enhanced mischief, or whether certain uses should be classed \\nas mischief at all, writes Tom Muir of Oslo Metropolitan University. \\nCan we detect AI-written content? A look at common features of large language \\nmodel-created writing and its implications for how educators might assess students’ \\nknowledge and skills in the future, by Cesare Giulio Ardito of the University of \\nManchester. \\nIs it time to turn off AI detectors? In this extract from their new book, ‘Teaching with AI: \\nA Practical Guide to a New Era of Human Learning’ , José Antonio Bowen and C. Edward \\nWatson discuss the reliability of AI detection tools and how to combat cheating without \\nthem. \\nHow hard can it be? Testing the dependability of AI detection tools: Students are \\nusing artificial intelligence to write essays and other assessment tasks, but can they\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load knowledge base documents\n",
    "loader = DirectoryLoader(DOCUMENT_FOLDER_PATH, glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "docs = loader.load()\n",
    "docs[:2]  # preview first two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e49e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-20T19:55:41+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-20T19:55:41+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\knowledge_base\\\\AI_and_assessment_in_higher_education.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='AI and assessment in higher education \\nhttps://www.timeshighereducation.com/campus/ai-and-assessment-higher-\\neducation  \\nThreat or opportunity? Advice for using, managing and embedding artificial intelligence \\nin university assessment, skills development and task design \\nNo sooner had generative AI (GenAI) tools, such as ChatGPT, ignited fears in universities \\nabout risk to assessment practices and academic integrity, than academics began \\nworking out how to embrace it to save time and enrich student skills such as critical \\nthinking and analysis. This has required consideration of not only how to use artificial \\nintelligence (AI) in future university assessment but also a rethink of past exam, \\nassignment and evaluation practices. This diverse collection of resources includes \\nadvice on how to engineer prompts, use AI for authentic assessment design, whether to \\nlean into AI-detection tools, how to build digital literacy and AI’s role in developing soft \\nskills in lifelong learning.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2024', 'creator': 'Microsoft® Word 2024', 'creationdate': '2025-12-20T19:55:41+08:00', 'author': 'hp404sk7@outlook.com', 'moddate': '2025-12-20T19:55:41+08:00', 'source': 'C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\knowledge_base\\\\AI_and_assessment_in_higher_education.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='lean into AI-detection tools, how to build digital literacy and AI’s role in developing soft \\nskills in lifelong learning. \\nGet started with 25 applications of ChatGPT and generative AI in learning and \\nassessment shared in the form of prompts by Seb Dianati and Suman Laudari of \\nCharles Darwin University. \\nHow AI can affect formative and summative assessment design \\nAs AI technologies become ubiquitous, educators must consider how to design \\nassignments that work with these tools in productive ways to aid learning and AI \\nliteracy. These resources explore practical ways to incorporate AI into task design and \\nassessment strategies, taking into account students’ differing skill levels.  \\nHow students’ GenAI skills and reflection affect assignment instructions: The \\nability to use GenAI is akin to time management or other learning skills that require \\npractice. Here, Vincent Spezzo and Ilya Gokhman from Georgia Tech’s Center for 21st')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "splits[:2]  # show first two splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7c251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define embeddings model\n",
    "#SiliconFlow hosts open-source embedding models that can be used with LangChain\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"BAAI/bge-m3\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=SILICON_FLOW_BASE_URL,\n",
    "    # Crucial for SiliconFlow/Local providers to avoid dimension errors\n",
    "    check_embedding_ctx_length=False,\n",
    "    chunk_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c0bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create vectorstore and retriever\n",
    "VECTOR_DATABASE_PATH = \"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\essay-checker-agentic-rag\\\\data\\\\chroma_db\"\n",
    "\n",
    "if os.path.exists(VECTOR_DATABASE_PATH):\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=VECTOR_DATABASE_PATH,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=\"essay_kb\")\n",
    "else:\n",
    "    vectorstore = Chroma.from_documents(\n",
    "            documents=splits, \n",
    "            embedding=embeddings,\n",
    "            collection_name=\"essay_kb\",\n",
    "            persist_directory=VECTOR_DATABASE_PATH\n",
    "        )\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdf87991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tool used to search knowledge base\n",
    "@tool \n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"Search the internal knowledge base of relevant essay documents.\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d90bef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tool used for web search\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web for relevant information.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48cf0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define output structure\n",
    "class FactEvaluation(BaseModel):\n",
    "    statement: str = Field(description=\"The original fact statement\")\n",
    "    correctness_score: Literal[\"correct\", \"wrong\", \"undetermined\"] = Field(description=\"The final verdict\")\n",
    "    summary_description: str = Field(description=\"Summary of why this verdict was reached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51082a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt enforcing the logic\n",
    "system_prompt = \"\"\"You are a fact-checking assistant. \n",
    "Logic Flow:\n",
    "1. For every fact, first use 'search_knowledge_base'.\n",
    "2. If the retrieved info supports the fact, mark as 'correct'.\n",
    "3. If it contradicts, mark as 'wrong'.\n",
    "4. If the knowledge base is insufficient (neutral/unknown), you MUST call 'web_search' ONCE to check online.\n",
    "5. If web results still don't clarify, mark as 'undetermined'.\n",
    "\n",
    "Return the result strictly as a JSON object matching the FactEvaluation schema.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37f01d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the tools\n",
    "tools = [search_knowledge_base, web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88852830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model used\n",
    "llm_model = ChatOpenAI(\n",
    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=\"https://api.siliconflow.cn/v1\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a336d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the agent\n",
    "agent = create_agent(\n",
    "    tools=tools,    \n",
    "    system_prompt=system_prompt,\n",
    "    model=llm_model,\n",
    "    name = \"FactCheckerAgent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfecddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "    \n",
    "with open(FACTS_JSONL_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        fact_data = json.loads(line)\n",
    "        statement = fact_data[\"statement\"]\n",
    "        \n",
    "        # Invoke agent for each fact\n",
    "        inputs = {\"messages\": [HumanMessage(content=f\"Evaluate this fact: {statement}\")]}\n",
    "        config = {\"configurable\": {\"thread_id\": \"fact_check\"}}\n",
    "        \n",
    "        # Use structured output parsing\n",
    "        response = agent.invoke(inputs)\n",
    "        # The last message contains the result. \n",
    "        # We can force the agent to return the structured schema\n",
    "        structured_llm = llm_model.with_structured_output(FactEvaluation)\n",
    "        final_eval = structured_llm.invoke(response[\"messages\"][-1].content)\n",
    "        \n",
    "        results.append(final_eval.dict())\n",
    "\n",
    "results[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
